{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## Simple RAG에서 Chunk 크기 평가하기\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) 파이프라인에서 **적절한 Chunk 크기를 설정하는 것**은 검색 정확도를 높이는 데 매우 중요합니다. 핵심은 **검색 성능과 응답 품질 사이의 균형**을 맞추는 것입니다.\n",
    "\n",
    "이 섹션에서는 다양한 Chunk 크기에 대해 아래와 같은 절차로 평가를 진행합니다:\n",
    "\n",
    "1. PDF에서 텍스트를 추출합니다.\n",
    "2. 텍스트를 여러 크기의 Chunk로 나눕니다.\n",
    "3. 각 Chunk에 대해 Embedding을 생성합니다.\n",
    "4. 쿼리에 대해 관련 있는 Chunk들을 검색합니다.\n",
    "5. 검색된 Chunk를 바탕으로 응답을 생성합니다.\n",
    "6. 생성된 응답의 \\*\\*사실성(faithfulness)\\*\\*과 \\*\\*관련성(relevancy)\\*\\*을 평가합니다.\n",
    "7. 서로 다른 Chunk 크기에서의 결과를 비교합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정하기\n",
    "필요한 라이브러리를 가져오는 것부터 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.environ.get('api_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API 클라이언트 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client_openai = OpenAI(api_key = API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF 파일에서 텍스트 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    # API 키 설정\n",
    "    genai.configure(api_key=gemini_API_KEY)\n",
    "    client = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
    "\n",
    "    # PDF 파일 업로드\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        file_data = file.read()\n",
    "\n",
    "\n",
    "    prompt = \"Extract all text from the provided PDF file.\"\n",
    "    response = client.generate_content([\n",
    "        {\"mime_type\": \"application/pdf\", \"data\": file_data},\n",
    "        prompt\n",
    "    ],generation_config={\n",
    "            \"max_output_tokens\": 8192  # 최대 출력 토큰 수 설정 (예: 8192 토큰, 약 24,000~32,000자)\n",
    "    })\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 핵심 개정세법\n",
      "01\n",
      "2024 달라지는 세금제도\n",
      "(국민·기업 납세자용)\n",
      "\n",
      "[유의사항]\n",
      "'2023 핵심 개정세법'은 국회에서 의결된 세법 개정사항을 모두 포괄하고 있으나, 시행령·\n",
      "시행규칙의 경우 2023.7월 발표한 ‘2023 세법개정안'을 중심으로 개정세법과 관련된 내용의\n",
      "경우 그대로 반영하였습니다. 그러므로 정부의 시행령, 시행규칙 개정 과정에서 일부 변동될\n",
      "수 있고 새로이 추가 제정될 수도 있습니다. 아울러 실무상 적용할 때는 반드시 개정세법의\n",
      "구체적인 조문을 확인하셔야 합니다.\n",
      "\n",
      "국민·기업 납세자용\n",
      "2024 달라지는 세금제도\n",
      "2024 달라지는 세금제도\n",
      "2023 세목별 핵심 개정세법\n",
      "2023 개정세법 현행-개정사항 비교\n",
      "01\n",
      "부동산 세금제도\n",
      "●(조특법) 연 단위 양도세 감면한도 악용방지를 위해 감면한도 산정방법 조정\n",
      "양도소득세 산정 및 감면이 연단위로 이뤄지는 점을 감안하여 ▲토지의 일부를\n",
      "양도한 날부터 소급하여 1년 내 토지를 분할한 경우 분필한 토지 또는 토지 지분\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 이미 text 파일로 저장되어 있다면 load_text_file 함수를 사용하면 됩니다.\n",
    "def load_text_file(pdf_path):\n",
    "\n",
    "    # text 파일 로드\n",
    "    with open(pdf_path, \"r\", encoding=\"utf-8\") as txt_file:\n",
    "        text = txt_file.read()\n",
    "\n",
    "    return text\n",
    "\n",
    "txt_path = \"./data_creation/pdf_data/(1) 2024 달라지는 세금제도.txt\"\n",
    "\n",
    "extracted_text = load_text_file(txt_path)\n",
    "print(extracted_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추출된 텍스트 청크 분할\n",
    "검색을 개선하기 위해 추출된 텍스트를 서로 다른 크기의 겹치는 청크로 분할했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 256, Number of Chunks: 135\n",
      "Chunk Size: 512, Number of Chunks: 68\n",
      "Chunk Size: 1024, Number of Chunks: 34\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    \"\"\"\n",
    "    주어진 텍스트를 겹치는 n개의 문자 세그먼트로 청크합니다.\n",
    "\n",
    "    Args:\n",
    "    text (str): 청크할 텍스트입니다.\n",
    "    n (int): 각 청크의 문자 수입니다.\n",
    "    overlap (int): 청크 간 겹치는 문자 수입니다.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: 청크된 텍스트 리스트입니다.\n",
    "    \"\"\"\n",
    "    chunks = []  # 청크된 텍스트를 저장할 빈 리스트를 초기화합니다.\n",
    "    \n",
    "    # (n - overlap) 단계로 텍스트를 반복합니다.\n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        # 인덱스 i부터 i + n까지의 텍스트를 청크 리스트에 추가합니다.\n",
    "        chunks.append(text[i:i + n])\n",
    "\n",
    "    return chunks  \n",
    "\n",
    "# 평가할 청크 크기를 정의합니다.\n",
    "chunk_sizes = [256, 512, 1024]\n",
    "\n",
    "# 각 청크 크기에 대한 텍스트 청크를 저장할 딕셔너리를 생성합니다.\n",
    "text_chunks_dict = {size: chunk_text(extracted_text, size, size // 5) for size in chunk_sizes}\n",
    "\n",
    "# Print the number of chunks created for each chunk size\n",
    "for size, chunks in text_chunks_dict.items():\n",
    "    print(f\"Chunk Size: {size}, Number of Chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분할된 청크의 임베딩 생성\n",
    "임베딩은 텍스트를 숫자 벡터로 변환하여 효율적인 유사도 검색을 가능하게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Batches: 100%|██████████| 34/34 [00:01<00:00, 17.35it/s]t/s]\n",
      "Batches: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s],  1.98s/it]\n",
      "Batches: 100%|██████████| 9/9 [00:00<00:00,  9.19it/s]01,  1.41s/it]\n",
      "Generating Embeddings: 100%|██████████| 3/3 [00:03<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "def create_embeddings(embedding_model, texts, device='cuda', batch_size=16):\n",
    "    \"\"\"\n",
    "    SentenceTransformer 모델을 사용하여 지정된 텍스트에 대한 임베딩을 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        embedding_model: 임베딩을 생성할 SentenceTransformer 모델입니다.\n",
    "        texts (list): 임베딩을 생성할 입력 텍스트 리스트입니다.\n",
    "        device (str): 모델을 실행할 장치 ('cuda' for GPU, 'cpu' for CPU).\n",
    "        batch_size (int): 인코딩을 위한 배치 크기입니다.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 모델에 의해 생성된 임베딩입니다.\n",
    "    \"\"\"\n",
    "    # 모델이 지정된 장치에 있는지 확인합니다.\n",
    "    embedding_model = embedding_model.to(device)\n",
    "    \n",
    "    # 지정된 배치 크기로 임베딩을 생성합니다.\n",
    "    embeddings = embedding_model.encode(\n",
    "        texts,\n",
    "        device=device,\n",
    "        batch_size=batch_size,  # 메모리 사용량을 줄이기 위해 더 작은 배치 크기를 사용합니다.\n",
    "        show_progress_bar=True  # 인코딩 진행 상태를 모니터링하기 위한 진행 표시줄을 표시합니다.\n",
    "    )\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# GPU 사용 가능 여부를 확인합니다.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델을 로드합니다.\n",
    "model = \"BAAI/bge-m3\"\n",
    "embedding_model = SentenceTransformer(model)\n",
    "\n",
    "# 각 청크 크기에 대한 임베딩을 생성합니다.\n",
    "chunk_embeddings_dict = {size: create_embeddings(embedding_model, chunks) for size, chunks in tqdm(text_chunks_dict.items(), desc=\"Generating Embeddings\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시맨틱 검색 수행하기\n",
    "코사인 유사도를 구현하여 사용자 쿼리에 가장 관련성이 높은 텍스트 청크를 찾습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    두 벡터 간의 코사인 유사도를 계산합니다.\n",
    "\n",
    "    Args:\n",
    "    vec1 (np.ndarray): 첫 번째 벡터입니다.\n",
    "    vec2 (np.ndarray): 두 번째 벡터입니다.\n",
    "\n",
    "    Returns:\n",
    "    float: 두 벡터 간의 코사인 유사도입니다.\n",
    "    \"\"\"\n",
    "    # 두 벡터의 내적을 계산하고 두 벡터의 크기의 곱으로 나눕니다.\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(query, text_chunks, chunk_embeddings, k=5):\n",
    "    \"\"\"\n",
    "    tok-k의 가장 유사한 청크를 검색\n",
    "    \n",
    "    Args:\n",
    "    query (str): 사용자 쿼리\n",
    "    text_chunks (List[str]): 텍스트 청크 리스트\n",
    "    chunk_embeddings (List[np.ndarray]): 텍스트 청크 임베딩 리스트\n",
    "    k (int): 상위 k개의 관련 텍스트 청크를 반환합니다. 기본값은 5입니다.\n",
    "    \n",
    "    Returns:\n",
    "    List[str]: 가장 유사한 상위 k개의 텍스트 청크 리스트\n",
    "    \"\"\"\n",
    "    # 쿼리에 대한 임베딩을 생성합니다.\n",
    "    query_embedding = create_embeddings(embedding_model, [query])[0]\n",
    "    \n",
    "    # 쿼리 임베딩과 각 청크 임베딩 간의 코사인 유사도를 계산합니다.\n",
    "    similarities = [cosine_similarity(query_embedding, emb) for emb in chunk_embeddings]\n",
    "    \n",
    "    # 가장 유사한 상위 k개의 청크의 인덱스를 추출합니다.\n",
    "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    \n",
    "    # 가장 유사한 상위 k개의 관련 텍스트 청크를 반환합니다.\n",
    "    return [text_chunks[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>generation_gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>피고의 고지의무 위반으로 인해 원고들이 입은 손해는 무엇으로 정의됩니까?</td>\n",
       "      <td>피고의 고지의무 위반으로 인해 원고들이 입은 손해는 \"이 사건 각 분양계약에 따른 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>지방공무원법 제53조는 공무원이 직무와 관련하여 무엇을 주거나 받을 수 없다고 규정...</td>\n",
       "      <td>지방공무원법 제53조는 공무원이 직무와 관련하여 직접적이든 간접적이든 사례, 증여 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>연금소득의 분리과세 기준금액은 얼마로 인상되었습니까?</td>\n",
       "      <td>연금소득의 분리과세 기준금액은 1천200만원에서 1천500만원으로 인상되었습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>공무원연금법 제65조 제1항 제1호에 의한 퇴직연금 등의 감액 요건은 무엇입니까?</td>\n",
       "      <td>공무원연금법 제65조 제1항 제1호에 의한 퇴직연금 등의 감액 요건은 재직 중 직무...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>권리사용료 산출방법에 대한 고시는 언제 개정되었습니까?</td>\n",
       "      <td>권리사용료 산출방법에 대한 고시는 2021년 3월 30일에 개정되었습니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0           피고의 고지의무 위반으로 인해 원고들이 입은 손해는 무엇으로 정의됩니까?   \n",
       "1  지방공무원법 제53조는 공무원이 직무와 관련하여 무엇을 주거나 받을 수 없다고 규정...   \n",
       "2                      연금소득의 분리과세 기준금액은 얼마로 인상되었습니까?   \n",
       "3      공무원연금법 제65조 제1항 제1호에 의한 퇴직연금 등의 감액 요건은 무엇입니까?   \n",
       "4                     권리사용료 산출방법에 대한 고시는 언제 개정되었습니까?   \n",
       "\n",
       "                                       generation_gt  \n",
       "0  피고의 고지의무 위반으로 인해 원고들이 입은 손해는 \"이 사건 각 분양계약에 따른 ...  \n",
       "1  지방공무원법 제53조는 공무원이 직무와 관련하여 직접적이든 간접적이든 사례, 증여 ...  \n",
       "2      연금소득의 분리과세 기준금액은 1천200만원에서 1천500만원으로 인상되었습니다.  \n",
       "3  공무원연금법 제65조 제1항 제1호에 의한 퇴직연금 등의 감액 요건은 재직 중 직무...  \n",
       "4          권리사용료 산출방법에 대한 고시는 2021년 3월 30일에 개정되었습니다.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 평가 데이터 로드하기\n",
    "df = pd.read_csv('./data_creation/rag_val_new_post.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.84it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['보호를 위해 비거주자·외국법인에 대한 조세조약상 비과세·면제 경\\n15\\n\\n한국세무사회\\n정청구 기한이 원천징수된 날이 속하는 달의 말일부터 5년 이내였던 것을 원천징\\n수세액 납부일의 다음 달 10일 이후부터 5년 이내 경정청구할 수 있도록 개선했다.\\n● (소득세법 시행령) 임직원의 국외주식 기준 보상 거래내역 제출의무 부여\\n내국법인이나 외국법인의 국내사업장의 임직원이 국외지배 주주인 외국법인으로부\\n터 받은 주식기준 보상 등을 행사하거나 지급받을 경우 주식 기', ' 전 소유권자의 체납세금이 있는지와 체납세금이 있\\n다면 법정기일이 저당권 등기일보다 빠른지를 파악해야 피해를 보지 않을 수 있다.\\n●(국세기본법) 상속재산 평가방법 차이에 대한 신고·납부지연가산세 적용 모두 제외\\n상속·증여재산 및 부담부 증여자산의 신고 시 해당 자산의 평가 차이로 인한 금\\n액에 대해서는 과소신고가산세는 명시 규정이 있으나 납부지연가산세에 대해서는\\n9\\n\\n한국세무사회\\n언급이 없어 과세될 수 있었으나, 과소신고가산세는 물론 납부지연가산세도 부', '과세표준을 신고하는 경우부터 적용)\\n●(국세기본법) 고발이나 통고처분과 관계없는 세목·세액은 과세전적부심사권 보장\\n과세전적부심사 적용제외 사유인 「조세범 처벌법」위반으로 고발 또는 통고처분\\n하는 상황에 해당하더라도, 고발 또는 통고처분과 관계없는 세목 또는 세액은 과세\\n전적부심사를 할 수 있도록 해 납세자의 권리보호를 강화했다.\\n●(국세징수법) 압류금지재산 또는 제3자 재산을 압류한 경우 압류 즉시 해제\\n압류금지재산을 압류하거나 제3자의 재산을 압류한 경', '부터 적용)\\n●(소득세법) 양도세 이월과세시 증여자 지출분 자본적 지출액도 필요경비로 공제\\n배우자 등으로부터 증여받은 후 증여받은 날로부터 10년 이내 양도한 경우. 양\\n도소득세 이월과세하는 경우 필요경비로 공제되는 자본적 지출액을 양도자가 지출\\n한 것뿐만 아니라 증여자가 지출한 자본적 지출액도 추가로 필요경비 공제를 받을\\n수 있도록 하였다.\\n(2024.1.1. 이후 양도분부터 적용)\\n●(국세기본법) 전세권 등으로 담보된 채권보다 우선징수하는 국세 범위 ', '손금·필\\n요경비로 인정된다. (영 시행일이 속하는 과세연도에 지출하는 분부터 적용)\\n● (조특법, 조특령) 기술혁신형 M&A에 대한 주식 등 취득기간 확대\\n인수법인이 피인수법인인 기술혁신형 중소기업 주식을 취득하는 경우 매입가액\\n중 기술가치 금액의 10%를 해당 사업연도의 법인세에서 공제할 때 당해연도 다음\\n사업연도 종료일까지 기준비율(50% 또는 최대주주인 경우 30%)의 초과 시점을 당\\n해연도 외에도 다음연도에 충족하는 경우도 세액공제를 받을 수 있도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가 데이터에서 첫 번째 쿼리를 추출합니다.\n",
    "query = df['query'][0]\n",
    "\n",
    "# 각 청크 크기에 대해 관련 청크를 검색합니다.\n",
    "retrieved_chunks_dict = {size: retrieve_relevant_chunks(query, text_chunks_dict[size], chunk_embeddings_dict[size]) for size in chunk_sizes}\n",
    "\n",
    "# 청크 크기 256에 대한 검색된 청크를 출력합니다.\n",
    "print(retrieved_chunks_dict[256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검색된 청크를 기반으로 응답 생성하기\n",
    "청크 크기 `256`에 대해 검색된 텍스트를 기반으로 응답을 생성해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Bmy6gyhK7OeEgtIBt3sokPEJpmfre', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='해당 질문에 답변할 충분한 정보가 없습니다.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1751010494, model='gpt-4.1-nano-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_38343a2f8f', usage=CompletionUsage(completion_tokens=13, prompt_tokens=981, total_tokens=994, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "def generate_response(system_prompt, query, retrieved_chunks, model_name='gpt-4.1-nona'):\n",
    "    # Combine retrieved chunks into a single context string\n",
    "    context = \"\\n\".join([f\"Context {i+1}:\\n{chunk}\" for i, chunk in enumerate(retrieved_chunks)])\n",
    "    \n",
    "    # Create the user prompt by combining the context and the query\n",
    "    user_prompt = f\"{context}\\n\\nQuestion: {query}\"\n",
    "\n",
    "    \n",
    "    response = client_openai.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    # print(response.choices[0].message.content)\n",
    "\n",
    "    return response\n",
    "\n",
    "# 시스템 프롬프트를 정의합니다.\n",
    "system_prompt = \"당신은 제공된 Context에 기반하여 답변하는 AI 어시스턴트입니다. 답변이 컨텍스트에서 직접 도출될 수 없는 경우, 다음 문장을 사용하세요: '해당 질문에 답변할 충분한 정보가 없습니다.'\"\n",
    "# 응답 생성\n",
    "# Generate AI responses for each chunk size\n",
    "ai_responses_dict = {size: generate_response(system_prompt, query,  retrieved_chunks_dict[size],'gpt-4.1-nano-2025-04-14') for size in chunk_sizes}\n",
    "\n",
    "# Print the response for chunk size 256\n",
    "print(ai_responses_dict[256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 질문에 답변할 충분한 정보가 없습니다.\n",
      "해당 질문에 답변할 충분한 정보가 없습니다.\n"
     ]
    }
   ],
   "source": [
    "print(ai_responses_dict[256].choices[0].message.content)\n",
    "print(ai_responses_dict[512].choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 생성 응답 평가하기\n",
    "생서 응답을 예상 답변과 비교하여 점수를 부여합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation scoring system constants\n",
    "SCORE_FULL = 1.0     # Complete match or fully satisfactory\n",
    "SCORE_PARTIAL = 0.5  # Partial match or somewhat satisfactory\n",
    "SCORE_NONE = 0.0     # No match or unsatisfactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define strict evaluation prompt templates\n",
    "FAITHFULNESS_PROMPT_TEMPLATE = \"\"\"\n",
    "Evaluate the faithfulness of the AI response compared to the true answer.\n",
    "User Query: {question}\n",
    "AI Response: {response}\n",
    "True Answer: {true_answer}\n",
    "\n",
    "Faithfulness measures how well the AI response aligns with facts in the true answer, without hallucinations.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Score STRICTLY using only these values:\n",
    "    * {full} = Completely faithful, no contradictions with true answer\n",
    "    * {partial} = Partially faithful, minor contradictions\n",
    "    * {none} = Not faithful, major contradictions or hallucinations\n",
    "- Return ONLY the numerical score ({full}, {partial}, or {none}) with no explanation or additional text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEVANCY_PROMPT_TEMPLATE = \"\"\"\n",
    "Evaluate the relevancy of the AI response to the user query.\n",
    "User Query: {question}\n",
    "AI Response: {response}\n",
    "\n",
    "Relevancy measures how well the response addresses the user's question.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Score STRICTLY using only these values:\n",
    "    * {full} = Completely relevant, directly addresses the query\n",
    "    * {partial} = Partially relevant, addresses some aspects\n",
    "    * {none} = Not relevant, fails to address the query\n",
    "- Return ONLY the numerical score ({full}, {partial}, or {none}) with no explanation or additional text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithfulness Score (Chunk Size 256): 0.0\n",
      "Relevancy Score (Chunk Size 256): 0.0\n",
      "\n",
      "\n",
      "Faithfulness Score (Chunk Size 512): 0.0\n",
      "Relevancy Score (Chunk Size 512): 0.0\n"
     ]
    }
   ],
   "source": [
    "def evaluate_response(question, response, true_answer, model='gpt-4.1-mini'):\n",
    "        \"\"\"\n",
    "        faithfulness와 relevancy을 기준으로 AI가 생성한 응답의 품질을 평가합니다.\n",
    "\n",
    "        Args:\n",
    "        question (str): 사용자의 원래 질문\n",
    "        response (str): 평가될 AI 생성 응답\n",
    "        true_answer (str): 정답으로 사용된 실제 답변\n",
    "\n",
    "        Returns:\n",
    "        Tuple[float, float]: (faithfulness_score, relevancy_score)\n",
    "        \"\"\"\n",
    "        # Format the evaluation prompts\n",
    "        faithfulness_prompt = FAITHFULNESS_PROMPT_TEMPLATE.format(\n",
    "                question=question, \n",
    "                response=response, \n",
    "                true_answer=true_answer,\n",
    "                full=SCORE_FULL,\n",
    "                partial=SCORE_PARTIAL,\n",
    "                none=SCORE_NONE\n",
    "        )\n",
    "        \n",
    "        relevancy_prompt = RELEVANCY_PROMPT_TEMPLATE.format(\n",
    "                question=question, \n",
    "                response=response,\n",
    "                full=SCORE_FULL,\n",
    "                partial=SCORE_PARTIAL,\n",
    "                none=SCORE_NONE\n",
    "        )\n",
    "        faithfulness_response = client_openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an objective evaluator. Return ONLY the numerical score.\"},\n",
    "                {\"role\": \"user\", \"content\": faithfulness_prompt}\n",
    "                ],\n",
    "        temperature=0.1,\n",
    "        top_p=0.9,\n",
    "        max_tokens=1024,\n",
    "        )\n",
    "        relevancy_response = client_openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an objective evaluator. Return ONLY the numerical score.\"},\n",
    "                {\"role\": \"user\", \"content\": relevancy_prompt}\n",
    "                ],\n",
    "        temperature=0.1,\n",
    "        top_p=0.9,\n",
    "        max_tokens=1024,\n",
    "        )\n",
    "\n",
    "        \n",
    "        # 점수를 추출하고 파싱 오류 처리\n",
    "        try:\n",
    "                faithfulness_score = float(faithfulness_response.choices[0].message.content.strip())\n",
    "        except ValueError:\n",
    "                print(\"Warning: Could not parse faithfulness score, defaulting to 0\")\n",
    "                faithfulness_score = 0.0\n",
    "                \n",
    "        try:\n",
    "                relevancy_score = float(relevancy_response.choices[0].message.content.strip())\n",
    "        except ValueError:\n",
    "                print(\"Warning: Could not parse relevancy score, defaulting to 0\")\n",
    "                relevancy_score = 0.0\n",
    "\n",
    "        return faithfulness_score, relevancy_score\n",
    "\n",
    "# 첫 번째 평가 데이터의 정답\n",
    "true_answer = df['generation_gt'][0]\n",
    "\n",
    "# 청크 크기 256과 512에 대한 응답 평가\n",
    "faithfulness, relevancy = evaluate_response(query, ai_responses_dict[256], true_answer, 'gpt-4.1-mini')\n",
    "faithfulness2, relevancy2 = evaluate_response(query, ai_responses_dict[512], true_answer, 'gpt-4.1-mini')\n",
    "\n",
    "# 평가 점수 출력\n",
    "print(f\"Faithfulness Score (Chunk Size 256): {faithfulness}\")\n",
    "print(f\"Relevancy Score (Chunk Size 256): {relevancy}\")\n",
    "\n",
    "print(f\"\\n\")\n",
    "\n",
    "print(f\"Faithfulness Score (Chunk Size 512): {faithfulness2}\")\n",
    "print(f\"Relevancy Score (Chunk Size 512): {relevancy2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
